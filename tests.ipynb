{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, h5py, json\n",
    "\n",
    "from utils import plot_data, return_best_chi2dof, plot_ref_data, BuildSample_DY, normalize, candidate_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildSample_DY_2(INPUT_PATH, seed, features=[], N_Events=-1, nfiles=20, shuffle=True):\n",
    "    np.random.seed(seed)\n",
    "    #random integer to select Zprime file between n files                                                                                                            \n",
    "    u = np.arange(nfiles)#np.random.randint(100, size=100)                                                                                                           \n",
    "    if shuffle: np.random.shuffle(u)\n",
    "    toy_label = INPUT_PATH.split(\"/\")[-2]\n",
    "    print(toy_label)\n",
    "    HLF = np.array([])\n",
    "    for u_i in u:\n",
    "        if not os.path.exists(INPUT_PATH+toy_label+str(u_i+1)+\".h5\"): continue\n",
    "        f    = h5py.File(INPUT_PATH+toy_label+str(u_i+1)+\".h5\", 'r')\n",
    "        keys = list(f.keys())\n",
    "        if u_i==u[0]:\n",
    "            print('available features: ', keys)\n",
    "        if len(keys)==0: continue #check whether the file is empty                                                                                                   \n",
    "        cols = np.array([])\n",
    "        if len(features): keys = features\n",
    "        for i in range(len(keys)):\n",
    "            feature = np.array(f.get(keys[i]))\n",
    "            feature = np.expand_dims(feature, axis=1)\n",
    "            if i==0: cols = feature\n",
    "            else: cols = np.concatenate((cols, feature), axis=1)\n",
    "        if shuffle: np.random.shuffle(cols) #don't want to select always the same event first                                                                       \\\n",
    "                                                                                                                                                                     \n",
    "        if HLF.shape[0]==0:\n",
    "            HLF=cols\n",
    "            i+=1\n",
    "        else: HLF=np.concatenate((HLF, cols), axis=0)\n",
    "        f.close()\n",
    "        if N_Events>0 and HLF.shape[0]>=N_Events:\n",
    "            HLF=HLF[:N_Events, : ]\n",
    "            break\n",
    "    print(HLF.shape)\n",
    "    #return HLF[:, [4, 5, 1, 2, 0, 3]]                                                                                                                               \n",
    "    return HLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_mll = 60\n",
    "cut_pt = 20\n",
    "cut_eta = 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiLepton_SM\n",
      "(3735456, 6)\n"
     ]
    }
   ],
   "source": [
    "#['delta_phi', 'eta1', 'eta2', 'mll', 'pt1', 'pt2'] how features are returned when loaded\n",
    "\n",
    "reference = BuildSample_DY(N_Events=3735456, INPUT_PATH='/data/marcol/HEPDATA/DILEPTON/DiLepton_SM/', rng=np.random.default_rng(seed=1234))\n",
    "#reference = BuildSample_DY_2('/data/marcol/HEPDATA/DILEPTON/DiLepton_SM/', 1234, features=['delta_phi', 'eta1', 'eta2', 'mll', 'pt1', 'pt2'], N_Events=-1, nfiles=66, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_idx = np.where((reference[:, 4] <= cut_pt) | (reference[:, 5] <= cut_pt) | (np.abs(reference[:, 1]) > cut_eta) | (np.abs(reference[:, 2]) > cut_eta) | (reference[:, 3] <= cut_mll))[0]\n",
    "masked_ref = np.delete(reference, mask_idx, axis=0)\n",
    "#mask = 1*(reference[:,3]>=cut_mll)*(np.abs(reference[:,1])<cut_eta)*(np.abs(reference[:,2])<cut_eta)*(reference[:,4]>=cut_pt)*(reference[:,5]>=cut_pt)\n",
    "#masked_ref = reference[mask>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masked_ref = masked_ref[:,]\n",
    "mean_R = np.mean(masked_ref, axis=0)\n",
    "std_R  = np.std(masked_ref, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.05212537e+00, 4.59876795e-04, 3.66978211e-04, 9.11198636e+01,\n",
       "       4.67488118e+01, 3.60544255e+01])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52342366,  1.24487457,  1.25051629, 15.86122412,  8.95046637])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "std_R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004598767946975146"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.mean(masked_ref[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.11986355771019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.mean(masked_ref[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./output/Ntoys100_NR200000_NB2000_NS90_nonres/t.txt\", \"r\") as fp:\n",
    "    # Load the dictionary from the file\n",
    "    t_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_array = []\n",
    "for key in t_dict.keys():\n",
    "    t_array.append(t_dict[key])\n",
    "t_array = np.array(t_array).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./output/Ntoys100_NR200000_NB2000_NS90_nonres/t_array.npy\",t_array)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
